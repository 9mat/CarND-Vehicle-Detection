{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noncar_supfolder = './data/non-vehicles/non-vehicles/'\n",
    "noncar_img_list = sorted(glob(noncar_supfolder +'*/*.png'))\n",
    "\n",
    "car_supfolder = './data/vehicles/vehicles/'\n",
    "car_img_list = sorted(glob(car_supfolder +'*/*.png'))\n",
    "\n",
    "print('Number of vehicle images:', len(car_img_list))\n",
    "print('Number of non-vehicle images:', len(noncar_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filelist2array(filelist):\n",
    "    out = []\n",
    "    for fn in filelist:\n",
    "        out.append(cv2.imread(fn))\n",
    "    return np.array(out, dtype=np.uint8)\n",
    "\n",
    "bags = 20\n",
    "car_imgs = filelist2array(car_img_list[:len(car_img_list)//bags*bags])\n",
    "noncar_imgs = filelist2array(noncar_img_list[:len(noncar_img_list)//bags*bags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_imgs = car_imgs.reshape(-1,bags,*car_imgs.shape[-3:])\n",
    "noncar_imgs = noncar_imgs.reshape(-1,bags,*noncar_imgs.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "car_train, car_test = train_test_split(car_imgs, test_size=0.2)\n",
    "noncar_train, noncar_test = train_test_split(noncar_imgs, test_size=0.2)\n",
    "\n",
    "car_train, car_val = train_test_split(car_train, test_size=0.25)\n",
    "noncar_train, noncar_val = train_test_split(noncar_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_train = car_train.reshape(-1,*car_train.shape[-3:])\n",
    "car_val = car_val.reshape(-1,*car_val.shape[-3:])\n",
    "car_test = car_test.reshape(-1,*car_test.shape[-3:])\n",
    "\n",
    "noncar_train = noncar_train.reshape(-1,*noncar_train.shape[-3:])\n",
    "noncar_val = noncar_val.reshape(-1,*noncar_val.shape[-3:])\n",
    "noncar_test = noncar_test.reshape(-1,*noncar_test.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def jitter_crop(img):\n",
    "    top = np.random.randint(0,64/4)\n",
    "    left = np.random.randint(0,64/4)\n",
    "    height = np.random.randint(64/2,64)\n",
    "    width = np.random.randint(64/2,64)\n",
    "    bottom = min(top+height, 64)\n",
    "    right = min(left+width, 64)\n",
    "    return cv2.resize(img[top:bottom, left:right], (64,64))\n",
    "\n",
    "def augment_data(imgs, n):\n",
    "    return [jitter_crop(img) for img in resample(imgs, n_samples=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# car_train = np.vstack([car_train, augment_data(car_train, 2*len(car_train))])\n",
    "# noncar_train = np.vstack([noncar_train, augment_data(noncar_train, 2*len(car_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.randint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_shape = car_train[0].shape\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "RGB = lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(RGB(car_train[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    yuv[:,:,0] = clahe.apply(yuv[:,:,0])\n",
    "    return cv2.cvtColor(img, cv2.COLOR_YUV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, cspace=None, size=(16, 16)):\n",
    "    # Convert image to new color space (if specified)\n",
    "    img = cv2.resize(img, size, cv2.INTER_AREA)\n",
    "    if cspace is not None:\n",
    "        img = cv2.cvtColor(img, cspace)\n",
    "    return img.ravel()\n",
    "\n",
    "def color_histogram(img,cspace=cv2.COLOR_BGR2HSV, bins=16):\n",
    "    if cspace is not None:\n",
    "        img = cv2.cvtColor(img, cspace)\n",
    "    return np.hstack([np.histogram(np.sqrt(channel).ravel(),bins=bins,normed=True)[0] \n",
    "                      for channel in cv2.split(img)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# help(cv2.HOGDescriptor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.feature\n",
    "\n",
    "def hog(img, orient=9, pix_per_cell=8, cell_per_block=2, vis=False, feature_vec=True):\n",
    "    return skimage.feature.hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "               cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "               visualise=vis, feature_vector=feature_vec)\n",
    "\n",
    "def hogcv(img, orient=32, pix_per_cell=7, cell_per_block=2):\n",
    "    hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // pix_per_cell * pix_per_cell,\n",
    "                                     img.shape[0] // pix_per_cell * pix_per_cell),\n",
    "                            _blockSize=(cell_per_block * pix_per_cell,\n",
    "                                       cell_per_block * pix_per_cell),\n",
    "                            _blockStride=(pix_per_cell, pix_per_cell),\n",
    "                            _cellSize=(pix_per_cell, pix_per_cell),\n",
    "                            _nbins=orient)\n",
    "    return hog.compute(img).ravel()\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_simple_features(img):\n",
    "    return np.hstack([bin_spatial(img,cv2.COLOR_BGR2HSV)])\n",
    "\n",
    "def extract_features(img):\n",
    "    y,cr,cb = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb))\n",
    "    return np.hstack([hogcv(y), hogcv(cr), hogcv(cb), bin_spatial(img, cv2.COLOR_BGR2HSV)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "simple_features_car_train = [extract_simple_features(img) for img in tqdm(car_train)]\n",
    "simple_features_noncar_train = [extract_simple_features(img) for img in tqdm(noncar_train)]\n",
    "simple_features_train = np.array(simple_features_car_train + simple_features_noncar_train)\n",
    "\n",
    "features_car_train = [extract_features(img) for img in tqdm(car_train)]\n",
    "features_noncar_train = [extract_features(img) for img in tqdm(noncar_train)]\n",
    "features_train = np.array(features_car_train + features_noncar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.array(simple_features_car_train).shape)\n",
    "np.array(features_car_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_train = [1]*len(features_car_train) + [0]*len(features_noncar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "feature_scaler = StandardScaler().fit(features_train)\n",
    "scaled_features_train = feature_scaler.transform(features_train)\n",
    "\n",
    "simple_feature_scaler = StandardScaler().fit(simple_features_train)\n",
    "scaled_simple_features_train = simple_feature_scaler.transform(simple_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "pca1 = PCA(n_components=50)\n",
    "pca1.fit(scaled_simple_features_train)\n",
    "\n",
    "pca_simple_features_train = pca1.transform(scaled_simple_features_train)\n",
    "# pca_simple_features_train = scaled_simple_features_train\n",
    "\n",
    "# classifier = GaussianNB()\n",
    "# classifier.fit(pca_simple_features_train, labels_train)\n",
    "\n",
    "classifier = LinearSVC(tol=1e-12)\n",
    "# classifier = SVC(tol=1e-8)\n",
    "# classifier = DecisionTreeClassifier()\n",
    "# classifier = AdaBoostClassifier()\n",
    "# classifier = LogisticRegressionCV(tol=1e-8)\n",
    "classifier.fit(pca_simple_features_train, labels_train)\n",
    "\n",
    "simple_features_car_test = [extract_simple_features(img) for img in tqdm(car_test)]\n",
    "simple_features_noncar_test = [extract_simple_features(img) for img in tqdm(noncar_test)]\n",
    "simple_features_test = np.array(simple_features_car_test + simple_features_noncar_test)\n",
    "\n",
    "labels_test = [1]*len(simple_features_car_test) + [0]*len(simple_features_noncar_test)\n",
    "\n",
    "scaled_simple_features_test = simple_feature_scaler.transform(simple_features_test)\n",
    "pca_simple_features_test = pca1.transform(simple_features_test)\n",
    "# pca_simple_features_test = simple_features_test\n",
    "pred_simple_test = classifier.predict(pca_simple_features_test)\n",
    "\n",
    "print('Test Precision of GNB = ', round(precision_score(labels_test, pred_simple_test), 4))\n",
    "print('Test Recall of GNB = ', round(recall_score(labels_test, pred_simple_test), 4))\n",
    "print('Test Accuracy of GNB = ', round(accuracy_score(labels_test, pred_simple_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_test = classifier.decision_function(pca_simple_features_test)\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels_test, scores_test)\n",
    "plt.plot(precision, recall,)\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=1000)\n",
    "# pca.fit(scaled_features_train)\n",
    "# print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pca_features_train = pca.transform(scaled_features_train)\n",
    "pca_features_train = scaled_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "svc.fit(pca_features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(img):\n",
    "    features = pack_features(img)\n",
    "    scaled_features = feature_scaler.transform(features)\n",
    "#     pca_features = pca.transform(scaled_features)\n",
    "    pca_features = scaled_features\n",
    "    return pca_features\n",
    "    \n",
    "features_car_test = [extract_features(img) for img in tqdm(car_test)]\n",
    "features_noncar_test = [extract_features(img) for img in tqdm(noncar_test)]\n",
    "features_test = np.array(features_car_test + features_noncar_test)\n",
    "\n",
    "labels_test = [1]*len(features_car_test) + [0]*len(features_noncar_test)\n",
    "\n",
    "scaled_features_test = feature_scaler.transform(features_test)\n",
    "# pca_features_test = pca.transform(scaled_features_test)\n",
    "pca_features_test = scaled_features_test\n",
    "\n",
    "print('Test Precision of SVC = ', round(precision_score(labels_test, svc.predict(pca_features_test)), 4))\n",
    "print('Test Recall of SVC = ', round(recall_score(labels_test, svc.predict(pca_features_test)), 4))\n",
    "print('Test Accuracy of SVC = ', round(svc.score(pca_features_test, labels_test), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is your draw_boxes function from the previous exercise\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    imcopy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)        \n",
    "    return imcopy\n",
    "\n",
    "def slide_window(img_shape, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    x_start, x_stop = x_start_stop\n",
    "    y_start, y_stop = x_start_stop\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img_shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img_shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = min(startx + xy_window[0], img_shape[1]-1)\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = min(starty + xy_window[1], img_shape[0]-1)\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "img_shape = img.shape\n",
    "\n",
    "windows192 = slide_window(img_shape, y_start_stop=[450, 600], \n",
    "                            xy_window=(192, 192), xy_overlap=(0.75, 0.75))\n",
    "windows128 = slide_window(img_shape, y_start_stop=[450, 600], \n",
    "                            xy_window=(128, 128), xy_overlap=(0.75, 0.75))\n",
    "windows96 = slide_window(img_shape, y_start_stop=[400, 520], \n",
    "                            xy_window=(96, 96), xy_overlap=(0.75, 0.75))\n",
    "windows64 = slide_window(img_shape, y_start_stop=[400, 550], \n",
    "                            xy_window=(64, 64), xy_overlap=(0.75, 0.75))\n",
    "windows = windows64 + windows96 + windows128 + windows192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(RGB(draw_boxes(img, windows64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def slide_window_extract_features(img, windows):\n",
    "    feature1 = np.array(slide_window_color_histogram(img, windows))\n",
    "    feature2 = np.array(slide_window_bin_spatial(img, windows))\n",
    "    feature3 = np.array(slide_window_hog(img, windows))\n",
    "    return np.hstack([feature1, feature2, feature3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features_from_windows(img, windows):\n",
    "    features = []\n",
    "    for (x0,y0), (x1,y1) in windows:\n",
    "        patch = cv2.resize(img[y0:y1,x0:x1], (64,64))\n",
    "        features.append(extract_features(patch))\n",
    "    return features\n",
    "\n",
    "def extract_simple_features_from_windows(img, windows):\n",
    "    features = []\n",
    "    for (x0,y0), (x1,y1) in windows:\n",
    "        patch = cv2.resize(img[y0:y1,x0:x1], (64,64))\n",
    "        features.append(extract_simple_features(patch))\n",
    "    return features\n",
    "\n",
    "def batch_extract_simple_features_from_windows(img, windows, binsize=(16,16)):\n",
    "    binh, binw = binsize\n",
    "    imgh, imgw = img.shape[:2]\n",
    "    \n",
    "    windows=np.int_(windows)\n",
    "    wsize = np.diff(windows,axis=1).squeeze()\n",
    "    unique_wsize = np.vstack({tuple(row) for row in wsize})\n",
    "    \n",
    "    patches = [None]*len(windows)\n",
    "    \n",
    "    for winw, winh in unique_wsize:\n",
    "        rs_img = cv2.resize(img, (binw*imgw//winw+1,binh*imgh//winh+1))            \n",
    "        idx, = np.where((wsize[:,0]==winh) &  (wsize[:,1]==winw))        \n",
    "        topleft = windows[idx][:,0,:]*[binw,binh]//[winw,winh]\n",
    "        for (x, y), i in zip(topleft, range(len(idx))):\n",
    "            patches[idx[i]] = rs_img[y:y+binh,x:x+binw]\n",
    "\n",
    "    return np.array(patches).reshape(len(windows),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect_veh(img):\n",
    "    features = extract_features_from_windows(img, windows)\n",
    "#     idx, = np.where(svc.predict(pca.transform(feature_scaler.transform(features)))>0.5)\n",
    "    idx, = np.where(svc.predict(feature_scaler.transform(features))>0.5)\n",
    "    return [windows[i] for i in idx]\n",
    "\n",
    "def simple_detect_veh(img):\n",
    "    features = batch_extract_simple_features_from_windows(img, windows)\n",
    "#     scores = classifier.predict(simple_feature_scaler.transform(features))\n",
    "    scaled_simple_features = simple_feature_scaler.transform(features)\n",
    "#     pca_simple_features = pca1.transform(scaled_simple_features)\n",
    "    pca_simple_features = scaled_simple_features\n",
    "    scores = classifier.predict(pca_simple_features)\n",
    "    idx, = np.where(scores>0.5)\n",
    "    return draw_boxes(img, [windows[i] for i in idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(img_shape, windows):\n",
    "    heatmap = np.zeros(img_shape[:2], dtype=int)\n",
    "    for (x0,y0), (x1,y1) in windows:\n",
    "        heatmap[y0:y1, x0:x1] += 1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "RGB = lambda x: cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.imread('test_images/test6.jpg')\n",
    "detected_windows = detect_veh(img)\n",
    "bboxed_img = draw_boxes(img, detected_windows)\n",
    "heatmap = add_heat(img.shape, detected_windows)\n",
    "plt.imshow(RGB(bboxed_img))\n",
    "plt.figure()\n",
    "plt.imshow(heatmap, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage.measurements\n",
    "from queue import Queue\n",
    "\n",
    "class History:\n",
    "    def __init__(self):\n",
    "        self.heatmaps = Queue(16)\n",
    "        self.bboxes = []\n",
    "        self.count = 0\n",
    "        self.decay = 0.8\n",
    "        \n",
    "    def update(self, img):\n",
    "        new_bboxes = detect_veh(img)\n",
    "        new_heatmap = add_heat(img.shape, new_bboxes)\n",
    "        if(self.heatmaps.full()): self.heatmaps.get()\n",
    "        self.heatmaps.put(new_heatmap)\n",
    "        intheatmaps = np.array(self.heatmaps.queue).sum(axis=0)\n",
    "        labels = scipy.ndimage.measurements.label(intheatmaps>5)\n",
    "        \n",
    "        bboxes = []\n",
    "        for veh in range(1, labels[1]+1):\n",
    "            nonzeroy, nonzerox = (labels[0] == veh).nonzero()\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            if bbox[1][0] - bbox[0][0] > 50 and bbox[1][1]-bbox[0][1] > 50:\n",
    "                bboxes.append(bbox)\n",
    "        \n",
    "        aaa = (intheatmaps*1.0/(intheatmaps.max()+0.01)*255).astype(np.uint8)\n",
    "        aaa = cv2.resize(aaa, (aaa.shape[1]//4, aaa.shape[0]//4))\n",
    "        aaa = cv2.cvtColor(aaa, cv2.COLOR_GRAY2BGR)\n",
    "        img = draw_boxes(img, bboxes)\n",
    "        img[:aaa.shape[0],:aaa.shape[1]] = aaa\n",
    "        return img\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "his = History()\n",
    "his.update(cv2.imread('./test_images/test1.jpg'))\n",
    "his.update(cv2.imread('./test_images/test1.jpg'))\n",
    "his.update(cv2.imread('./test_images/test1.jpg'))\n",
    "his.update(cv2.imread('./test_images/test1.jpg'))\n",
    "plt.imshow(RGB(his.update(cv2.imread('./test_images/test1.jpg'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "his = History()\n",
    "\n",
    "rgb2bgr = lambda x: cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n",
    "input_name = './project_video.mp4'\n",
    "output_name = './project_video_out.mp4'\n",
    "clip1 = VideoFileClip(input_name)\n",
    "white_clip = clip1.fl_image(lambda x: RGB(his.update(rgb2bgr(x)))) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output_name, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.HOGDescriptor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:traffic]",
   "language": "python",
   "name": "conda-env-traffic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
